# fetch_10min.py â€”â€” å…ˆåŒæ­¥ stations/datastreamsï¼Œå†æŠ“è¿‘ WINDOW_MIN åˆ†é˜è§€æ¸¬ï¼ˆæ”¯æ´ é›¨é‡/æ°´ä½/æµé‡ï¼‰
import json, requests
from datetime import datetime, timedelta, timezone

from common import (
    ensure_conn,
    fetch_paged,
    _get,
    to_utc_dt,
    classify_metric_from_ds,   # åŠ å¼·ç‰ˆåˆ†é¡ï¼ˆç¶œåˆ name/ObservedProperty/unitï¼‰
)
from app_config import BASE_URLS, WINDOW_MIN


def iter_sources(path_suffix: str):
    for base in BASE_URLS:
        yield base, f"{base.rstrip('/')}/{path_suffix.lstrip('/')}"


THINGS_PATH = "Things"


def sync_catalog(conn):
    """
    åŒæ­¥ stations / datastreams é€² DBã€‚
    é€™è£¡èµ°ã€Œé€ç«™ â†’ å– Datastreamsï¼ˆå±•é–‹ ObservedPropertyï¼‰ã€çš„ä¿å®ˆè·¯å¾‘ï¼Œä»¥ç›¸å®¹å„åº«ç«¯é»ã€‚
    è‹¥è¦ºå¾—å¤ªæ…¢ï¼Œå¯ä»¥å†æ›æˆã€Œç›´æ¥æƒ /Datastreams?$expand=Thing,ObservedPropertyã€çš„å¿«é€Ÿç‰ˆã€‚
    """
    any_ok = False
    for base, things_url in iter_sources(THINGS_PATH):
        try:
            for thing in fetch_paged(things_url):
                any_ok = True
                thing_id = thing.get("@iot.id")
                thing_name = thing.get("name")
                props = thing.get("properties")

                conn.execute(
                    "INSERT OR REPLACE INTO stations(thing_id, thing_name, thing_properties) VALUES(?,?,?)",
                    (thing_id, thing_name, json.dumps(props, ensure_ascii=False)),
                )

                # å±•é–‹ ObservedProperty ä»¥æå‡åˆ†ç¾¤æº–ç¢ºç‡
                ds_url = f"{base.rstrip('/')}/Things({thing_id})/Datastreams?$expand=ObservedProperty"
                for ds in fetch_paged(ds_url):
                    ds_id = ds.get("@iot.id")
                    ds_name = ds.get("name")
                    metric = classify_metric_from_ds(ds)  # å¯èƒ½å¾—åˆ° rainfall / water_level / discharge / ''
                    unit = (ds.get("unitOfMeasurement") or {}).get("name")

                    conn.execute(
                        "INSERT OR REPLACE INTO datastreams(ds_id, thing_id, ds_name, metric, unit) VALUES(?,?,?,?,?)",
                        (ds_id, thing_id, ds_name, metric, unit),
                    )

        except requests.HTTPError as e:
            if e.response is not None and e.response.status_code in (404, 410):
                # é€™å€‹ BASE_URL æ²’æœ‰å°æ‡‰è³‡æºï¼Œç•¥éå³å¯
                print("âš ï¸ source not found:", things_url)
                continue
            raise

    conn.commit()
    if not any_ok:
        raise RuntimeError(
            "No sources yielded data. è«‹ç¢ºèª app_config.BASE_URLSï¼ˆå…ˆç”¨ STA_Rain/v1.0 é©—è­‰ï¼‰ã€‚"
        )


def fetch_recent_observations(conn):
    """æŠ“è¿‘ WINDOW_MIN åˆ†é˜çš„ Observationsï¼Œå»é‡å¾Œå¯«é€² raw_observationsã€‚"""
    since_utc = datetime.utcnow().replace(tzinfo=timezone.utc) - timedelta(minutes=WINDOW_MIN)

    # åªæŠ“ã€Œå·²åˆ¤å‡º metric çš„ datastreamã€
    cur = conn.execute("SELECT ds_id, thing_id FROM datastreams WHERE metric != ''")
    rows = cur.fetchall()

    for ds_id, thing_id in rows:
        found = False
        for base in BASE_URLS:
            obs_url = f"{base.rstrip('/')}/Datastreams({ds_id})/Observations"
            params = {
                "$filter": f"phenomenonTime ge {since_utc.isoformat()}",
                "$orderby": "phenomenonTime asc",
                "$top": 1000,
            }
            try:
                data = _get(obs_url, params)
                for obs in data.get("value", []):
                    t_utc = to_utc_dt(obs.get("phenomenonTime")).isoformat()
                    result = obs.get("result")
                    conn.execute(
                        "INSERT OR IGNORE INTO raw_observations(ds_id, thing_id, obs_time_utc, result, result_json) "
                        "VALUES(?,?,?,?,?)",
                        (
                            ds_id,
                            thing_id,
                            t_utc,
                            float(result) if result is not None else None,
                            json.dumps(obs, ensure_ascii=False),
                        ),
                    )
                found = True
                break
            except requests.HTTPError as e:
                if e.response is not None and e.response.status_code in (404, 410):
                    # æ­¤åº«æ²’æœ‰é€™å€‹ ds_id çš„ Observationsï¼Œæ›ä¸‹ä¸€å€‹ BASE_URL å˜—è©¦
                    continue
                else:
                    raise
        if not found:
            print(f"âš ï¸ no observation endpoint for ds_id={ds_id} in configured BASE_URLS")

    conn.commit()


if __name__ == "__main__":
    conn = ensure_conn()
    print("ğŸ”„ syncing catalog (stations & datastreams)...")
    sync_catalog(conn)
    print("ğŸ”„ fetching recent observations (last", WINDOW_MIN, "minutes)...")
    fetch_recent_observations(conn)
    conn.close()
    print("âœ… Done fetching recent observations")
